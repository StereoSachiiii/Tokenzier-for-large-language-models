this is made with simple "for" loops .  while this code might compress the text to a point until there are no adjacent repeating pairs  its obviously not reccomended for an actual ai im just tryna learn . In another version i will  try to take the token sequence legnth , symbols tradeoff(get the sweet spot because i know if you run this algorithms in like 1tb of text data your pc would probably explode because there will be like a billion tokens probably haha and 0(n^2) complexity). in the next iteration and i will make a tokenizor app using html/css/js to visualze it!
